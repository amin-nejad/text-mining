{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import requests\n",
    "import justext\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedEntityRecognition:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \n",
    "        self.url = url\n",
    "        self.companies = []\n",
    "        self.people = []\n",
    "        self.keywords = []\n",
    "        self.locations = []\n",
    "        self.events = []\n",
    "        self.products = []\n",
    "        self.text = None\n",
    "        self.doc = None\n",
    "        \n",
    "    def visualise(self):\n",
    "        if str(self.doc) != \"\":\n",
    "            return displacy.render(self.doc, style=\"ent\", jupyter=True)\n",
    "        else:\n",
    "            return \"No entities found.\"\n",
    "    \n",
    "    def jsonify(self):\n",
    "        \n",
    "        list_of_entities = [self.companies, self.people, self.keywords, self.locations, self.events, self.products]\n",
    "        list_of_entity_types = [\"companies\", \"people\", \"keywords\", \"locations\", \"events\", \"products\"]\n",
    "        zip_object = zip(list_of_entity_types, list_of_entities)\n",
    "        entity_dict = dict(zip_object)\n",
    "        \n",
    "        return json.dumps(entity_dict, sort_keys=True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        sources=pd.read_csv(filename,header=None,names=[\"url\"])\n",
    "        #sources=sources.append({\"url\":\"www.balsejfnweo.com\"}, ignore_index = True) \n",
    "        \n",
    "        self.sources = sources.head()\n",
    "        self.bad_urls = []\n",
    "        self.extracted = self.__extract_text()\n",
    "        self.ner_list = None\n",
    "        \n",
    "        if \"__remove_whitespace_entities\" not in (dict(nlp.pipeline).keys()):\n",
    "            nlp.add_pipe(self.__remove_whitespace_entities, after='ner')\n",
    "\n",
    "    def __extract_text(self):\n",
    "        \n",
    "        extracted=[]\n",
    "        for url in self.sources['url']:\n",
    "\n",
    "            url = \"http://\"+url\n",
    "            \n",
    "            try:\n",
    "                html = requests.get(url)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self.bad_urls.append(url)\n",
    "                print (e)\n",
    "                \n",
    "            if str(html) == \"<Response [200]>\":\n",
    "                \n",
    "                text = \"\"\n",
    "                paragraphs = justext.justext(html.text.encode('utf-8'), justext.get_stoplist(\"English\"))\n",
    "                for paragraph in paragraphs:\n",
    "                    if not paragraph.is_boilerplate:\n",
    "                        text+= paragraph.text + \"\\n\"\n",
    "            else:\n",
    "                text=\"<ERROR>\"\n",
    "\n",
    "            extracted.append(text)\n",
    "\n",
    "        return extracted\n",
    "    \n",
    "    def __remove_whitespace_entities(self, doc):\n",
    "        doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "        return doc\n",
    "    \n",
    "    def extract_entities(self):\n",
    "        \n",
    "        ner_list=[]\n",
    "        \n",
    "        for i, url in enumerate(self.sources['url']):\n",
    "            ner_list.append(NamedEntityRecognition(url))\n",
    "            \n",
    "            doc = nlp(self.extracted[i])\n",
    "            ner_list[i].text = self.extracted[i]\n",
    "            ner_list[i].doc = doc\n",
    "            \n",
    "            for entity in doc.ents:\n",
    "                if (entity.label_ == \"ORG\"):\n",
    "                    ner_list[i].companies.append(entity.text)\n",
    "                elif (entity.label_ == \"PERSON\"):\n",
    "                    ner_list[i].people.append(entity.text)\n",
    "                elif (entity.label_ == \"GPE\"):\n",
    "                    ner_list[i].locations.append(entity.text)            \n",
    "                elif (entity.label_ == \"EVENT\"):\n",
    "                    ner_list[i].events.append(entity.text)        \n",
    "                elif (entity.label_ == \"PRODUCT\"):\n",
    "                    ner_list[i].products.append(entity.text)\n",
    "        \n",
    "        self.ner_list = ner_list\n",
    "        return\n",
    "        \n",
    "    def get_number_of_urls(self):\n",
    "        return len(self.sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=Extract(\"./sources.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.bad_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.extract_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UK', 'Devon', 'UK', 'UK', 'Ireland', 'UK', 'UK', 'Scroll']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ner_list[4].locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No entities found.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ner_list[0].visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"companies\": [\n",
      "        \"The Independent Corrugated Cardboard Packaging\\nSpecialists\\nProducts\\n\",\n",
      "        \"Innovation, Leadership, Team work and Excellence\"\n",
      "    ],\n",
      "    \"events\": [],\n",
      "    \"keywords\": [],\n",
      "    \"locations\": [\n",
      "        \"UK\",\n",
      "        \"Devon\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Ireland\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Scroll\"\n",
      "    ],\n",
      "    \"people\": [\n",
      "        \"Atlas Packaging\",\n",
      "        \"Vimeo\"\n",
      "    ],\n",
      "    \"products\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(test.ner_list[4].jsonify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
