{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import requests\n",
    "import justext\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import json\n",
    "import wikipedia\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "import os\n",
    "import subprocess\n",
    "from neo4j import GraphDatabase\n",
    "from pathlib import Path\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we create a NamedEntityRecognition class. Each object of this class will represent a given webpage and specifically hold the information regarding the named entities present within the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedEntityRecognition:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: url of the webpage as a string\n",
    "        \n",
    "        Just instantiates all the lists of named entities\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.url = url\n",
    "        self.companies = []\n",
    "        self.people = []\n",
    "        self.keywords = []\n",
    "        self.locations = []\n",
    "        self.events = []\n",
    "        self.products = []\n",
    "        self.text = None\n",
    "        self.doc = None\n",
    "        \n",
    "    def visualise(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Returns a html rendered visualisation of the named entities within the homepage of the url using displacy\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if str(self.doc) != \"\":\n",
    "            return displacy.render(self.doc, style=\"ent\", jupyter=True)\n",
    "        else:\n",
    "            return \"No entities found.\"\n",
    "    \n",
    "    def jsonify(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Returns a json version of all the named entities within the webpage\n",
    "        \"\"\"\n",
    "        \n",
    "        list_of_entities = [self.companies, self.people, self.keywords, self.locations, self.events, self.products]\n",
    "        list_of_entity_types = [\"companies\", \"people\", \"keywords\", \"locations\", \"events\", \"products\"]\n",
    "        zip_object = zip(list_of_entity_types, list_of_entities)\n",
    "        entity_dict = dict(zip_object)\n",
    "        \n",
    "        return json.dumps(entity_dict, indent = 4, ensure_ascii=False)\n",
    "    \n",
    "    def get_people_wiki_pages(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Returns a dictionary consisting of the people identified within the webpage as the key, whilst the value attempts\n",
    "        to return the url and first line of the article for the closest match to the person on wikipedia\n",
    "        \n",
    "        *** STILL NEEDS WORK, RETURNS UNEXPECTED RESULTS IF THE PERSON IS NOT ON WIKIPEDIA ***\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        wiki = []\n",
    "        \n",
    "        for person in self.people:\n",
    "            try:\n",
    "                result = wikipedia.page(person)\n",
    "                summary = wikipedia.summary(person, sentences=1)\n",
    "                wiki.append([result.url, summary])\n",
    "            except:\n",
    "                wiki.append([\"\",\"\"])\n",
    "        zip_object = zip(self.people, wiki)\n",
    "        \n",
    "        return dict(zip_object)\n",
    "\n",
    "    def __get_links(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Private function which attempts to extract all the relevant links from the original webpage that point to other\n",
    "        pages on the same website and returns the urls in a list\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        new_url = \"http://\" + self.url\n",
    "        html=requests.get(new_url)\n",
    "        links = []\n",
    "\n",
    "        for link in BeautifulSoup(html.text, parse_only=SoupStrainer('a')):\n",
    "            try:\n",
    "                new_link = (link['href'])\n",
    "\n",
    "                short_url = self.url[4:]\n",
    "                if (new_link.find(short_url) >= 0) and (new_link.count('@') == 0):\n",
    "                    idx=new_link.find(short_url) + len(short_url)\n",
    "                    end=new_link.find('/',idx+1)\n",
    "                    if end == -1:\n",
    "                        end = len(new_link)\n",
    "                    links.append(new_link[:end])\n",
    "\n",
    "                elif (new_link.count('/', 1) <= 1) and (str(new_link)[:4] != \"http\") and (new_link.count('#') == 0) and (new_link.count('@') == 0):\n",
    "\n",
    "                    if (new_link.count('/', 1) == 1) and (new_link[:-1] != \"/\"):\n",
    "                        continue\n",
    "                    links.append(self.url + new_link)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        return list(set(links))\n",
    "    \n",
    "    def get_salience(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Returns a measure of the relative importance of all the named entities. It attempts to do this by simply counting the\n",
    "        frequency of all the terms both on the webpage and on all the other relevant pages to which the original page links \n",
    "        using the __get_links() method. The function then returns a dictionary in descending order of count.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        corpus=[self.text]\n",
    "        links = self.__get_links()\n",
    "\n",
    "        for link in links:\n",
    "\n",
    "            if (link[:4] != \"http\"):\n",
    "                link = \"http://\" + link\n",
    "\n",
    "            try:\n",
    "                html = requests.get(link)\n",
    "            except:\n",
    "                html=\"\"\n",
    "            \n",
    "            text = \"\"\n",
    "            if str(html) == \"<Response [200]>\":\n",
    "                \n",
    "                try:\n",
    "                    paragraphs = justext.justext(html.text.encode('utf-8'), justext.get_stoplist(\"English\"))\n",
    "                    for paragraph in paragraphs:\n",
    "                        if not paragraph.is_boilerplate:\n",
    "                            text+= paragraph.text + \"\\n\"\n",
    "                except:\n",
    "                    print(\"Could not parse text\")\n",
    "            corpus.append(text)\n",
    "\n",
    "        all_entities = self.companies + self.people + self.keywords + self.locations + self.events + self.products\n",
    "        counts = []\n",
    "        \n",
    "        for entity in all_entities:\n",
    "            counts.append(sum(entity in s for s in corpus))\n",
    "        \n",
    "        entity_dict = dict(zip(all_entities, counts))\n",
    "        \n",
    "        return {k: v for k, v in sorted(entity_dict.items(), key=lambda x: x[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an object which parses a file containing a list of urls and extracts content from the webpages, including named entities, storing them in instances of the NamedEntityRecognition class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    \n",
    "    def __init__(self, csv_or_url):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: filename containing a list of url strings (with 'url' header) or an individual url string\n",
    "        \n",
    "        Takes a list of urls or single url and initialises some variables. \n",
    "        Adds a function removing whitespace to the spacy pipeline if it has not already been added\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        my_file = Path(csv_or_url)\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            sources=pd.read_csv(csv_or_url,header=None,names=[\"url\"])\n",
    "        else:\n",
    "            sources = pd.DataFrame({'url':csv_or_url}, index=[0])\n",
    "        \n",
    "        self.sources = sources\n",
    "        self.bad_urls = []\n",
    "        self.extracted = self.__extract_text()\n",
    "        self.ner_list = None\n",
    "        \n",
    "        if \"__remove_whitespace_entities\" not in (dict(nlp.pipeline).keys()):\n",
    "            nlp.add_pipe(self.__remove_whitespace_entities, after='ner')\n",
    "\n",
    "    def __extract_text(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Private function which is called on initiliatisation of the object. Loops through every url in the list and extracts\n",
    "        non-boilerplate content before saving it as list. Keeps track of urls which are either broken or timeout before\n",
    "        returning the webpage and saves it in the data member \"bad_urls\"\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        extracted=[]\n",
    "        for url in self.sources['url']:\n",
    "\n",
    "            url = \"http://\"+url\n",
    "            \n",
    "            try:\n",
    "                html = requests.get(url)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self.bad_urls.append(url)\n",
    "                print (e)\n",
    "            \n",
    "            if str(html) == \"<Response [200]>\":\n",
    "                \n",
    "                text = \"\"\n",
    "                paragraphs = justext.justext(html.text.encode('utf-8'), justext.get_stoplist(\"English\"))\n",
    "                for paragraph in paragraphs:\n",
    "                    if not paragraph.is_boilerplate:\n",
    "                        text+= paragraph.text + \"\\n\"\n",
    "            else:\n",
    "                text=\"<ERROR>\"\n",
    "\n",
    "            extracted.append(text)\n",
    "\n",
    "        return extracted\n",
    "    \n",
    "    def __remove_whitespace_entities(self, doc):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: string representing an individual document\n",
    "        \n",
    "        A function added to the spacy pipeline due to a bug in spacy which results in certain whitespace characters being \n",
    "        recognised as entities: https://github.com/explosion/spaCy/issues/2870\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "        return doc\n",
    "        \n",
    "    def extract_entities(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Uses the spacy namer entity recogniser to extract named entities from the non-boilerplate content of each webpage.\n",
    "        Additionally uses the Rake algorithm to extract keywords from the same non-boilerplate content. Creates an instance of\n",
    "        the NamedEntityRecognition class for each webpage and stores the addresses to the objects in a list called \"ner_list\"\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ner_list=[]\n",
    "        r = Rake()\n",
    "        k = 10 #top number of key words to extract\n",
    "\n",
    "        for i, url in enumerate(self.sources['url']):\n",
    "            ner_list.append(NamedEntityRecognition(url))\n",
    "            \n",
    "            ner_list[i].text = self.extracted[i]\n",
    "            r.extract_keywords_from_text(ner_list[i].text)\n",
    "            top_k_keywords = [value for value in dict(r.get_ranked_phrases_with_scores()[:k]).values()]\n",
    "            ner_list[i].keywords = top_k_keywords\n",
    "            \n",
    "            doc = nlp(self.extracted[i])\n",
    "            ner_list[i].doc = doc\n",
    "            \n",
    "            for entity in doc.ents:\n",
    "                if (entity.label_ == \"ORG\"):\n",
    "                    ner_list[i].companies.append(entity.text)\n",
    "                elif (entity.label_ == \"PERSON\"):\n",
    "                    ner_list[i].people.append(entity.text)\n",
    "                elif (entity.label_ == \"GPE\"):\n",
    "                    ner_list[i].locations.append(entity.text)            \n",
    "                elif (entity.label_ == \"EVENT\"):\n",
    "                    ner_list[i].events.append(entity.text)        \n",
    "                elif (entity.label_ == \"PRODUCT\"):\n",
    "                    ner_list[i].products.append(entity.text)\n",
    "        \n",
    "        self.ner_list = ner_list\n",
    "        return\n",
    "        \n",
    "    def get_number_of_urls(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args: None\n",
    "        \n",
    "        Simple function to just return the number of urls in the input file\n",
    "        \n",
    "        \"\"\"\n",
    "        return len(self.sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a class for adding our extracted entities and keywords to a neo4j graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4j:\n",
    "    \n",
    "    def __init__(self, NER_object):\n",
    "        \"\"\"\n",
    "        Args: an object of type NamedEntityRecognition\n",
    "        \n",
    "        Takes an object of type NamedEntityRecognition and extracts the url and JSON from the object. \n",
    "        Also connects to a neo4j database.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.uri = \"bolt://localhost:7687\"\n",
    "        self.driver = GraphDatabase.driver(self.uri, auth=(\"neo4j\", \"4jNeo\"))\n",
    "        self.json = json.loads(NER_object.jsonify())\n",
    "        self.url = NER_object.url\n",
    "        self.salience = NER_object.get_salience()\n",
    "        \n",
    "    def __create_query(self, tx, test):\n",
    "        \"\"\"\n",
    "        Args: a neo4j driver session\n",
    "        \n",
    "        Internal function which creates and runs the query that extracts the information from the JSON and\n",
    "        inserts them as nodes into the neo4j graph.\n",
    "        \"\"\"\n",
    "        temp_id = 1\n",
    "        query = (\"CREATE (name:website {url:'\"+self.url+\"'})\")\n",
    "        for i in self.json:\n",
    "            for j in self.json[i]:\n",
    "                query += \" CREATE (node\" + str(temp_id) + \":\" + i + \" {name:'\"+j+\"', salience:\" + str(self.salience[j]) +\"})\"\n",
    "                query += \" CREATE (node\" + str(temp_id) + \")-[:EXTRACTED_FROM]->(name)\"\n",
    "                temp_id += 1\n",
    "        if test is False: tx.run(query)\n",
    "        \n",
    "        print (\"Nodes added to graph:\", temp_id)\n",
    "                \n",
    "    def add_nodes(self, test=False):\n",
    "        \"\"\"\n",
    "        Args: none\n",
    "        \n",
    "        External function which calls __create_function from a neo4j driver session\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.read_transaction(self.__create_query, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now instantiate our class and see what our webpages have to offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages = Extract(\"./sources.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages.bad_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpages.extract_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.atlaspackaging.co.uk'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages.ner_list[4].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The Independent Corrugated Cardboard Packaging\n",
       "Specialists\n",
       "Products\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "What we make</br>Here at Atlas Packaging we are a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " cardboard box manufacturer making all types of corrugated cardboard packaging from our base in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Devon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". This means that since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1983\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " we’ve been reliably designing and making corrugated packaging across a range of industries. We pride ourselves on delivering competitive prices, clear quotations and excellent service. To do this we have in house award winning structural and graphic design teams and state of the art production equipment.</br>Scroll up and down the list to choose your box type. But if you don’t see the design you want then let us know because as the leading independent \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " cardboard box manufacturer we can make almost anything out of cardboard.</br>How we do it</br>We have in-house structural and graphic design teams who guide your packaging through the entire production process. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Secondly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", we have some of the best production machinery in the business to produce high quality corrugated cardboard packaging at competitive prices. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Thirdly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", we have warehousing to store \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    thousands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of pallets and a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ireland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " wide delivery fleet. All of this guarantees that \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Atlas Packaging\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", as the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "’s leading independent cardboard box manufacturer, is the perfect choice for your box requirements. If you like the videos that you have seen so far on our website then please visit our \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Vimeo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " channel for more of them.</br>Who we work with</br>At every stage of our production we remember our company values of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Innovation, Leadership, Team work and Excellence\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". This approach to doing business means that we work with some of the leading brands in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " across a wide range of industries. Because of this we love the challenge of producing innovative and distinctive corrugated cardboard packaging for businesses who don’t always want the same old type of packaging.</br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Scroll\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " over the list to see what packaging solutions we can provide for your type of business.\n",
       "Need a quote fast?\n",
       "Or want to speak to us? If you’re interested in a quote or just want to discuss a new project, fill\n",
       "out our quick request form and a member of our skillful and qualified team will be in touch with you\n",
       "shortly.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "webpages.ner_list[4].visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"companies\": [\n",
      "        \"The Independent Corrugated Cardboard Packaging\\nSpecialists\\nProducts\\n\",\n",
      "        \"Innovation, Leadership, Team work and Excellence\"\n",
      "    ],\n",
      "    \"people\": [\n",
      "        \"Atlas Packaging\",\n",
      "        \"Vimeo\"\n",
      "    ],\n",
      "    \"keywords\": [\n",
      "        \"produce high quality corrugated cardboard packaging\",\n",
      "        \"independent corrugated cardboard packaging specialists products\",\n",
      "        \"leading independent uk cardboard box manufacturer\",\n",
      "        \"leading independent cardboard box manufacturer\",\n",
      "        \"uk cardboard box manufacturer making\",\n",
      "        \"distinctive corrugated cardboard packaging\",\n",
      "        \"making corrugated packaging across\",\n",
      "        \"ireland wide delivery fleet\",\n",
      "        \"house award winning structural\",\n",
      "        \"corrugated cardboard packaging\"\n",
      "    ],\n",
      "    \"locations\": [\n",
      "        \"UK\",\n",
      "        \"Devon\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Ireland\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Scroll\"\n",
      "    ],\n",
      "    \"events\": [],\n",
      "    \"products\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(webpages.ner_list[4].jsonify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atlas Packaging': 22,\n",
       " 'corrugated cardboard packaging': 14,\n",
       " 'UK': 14,\n",
       " 'Devon': 8,\n",
       " 'Ireland': 8,\n",
       " 'The Independent Corrugated Cardboard Packaging\\nSpecialists\\nProducts\\n': 4,\n",
       " 'Innovation, Leadership, Team work and Excellence': 4,\n",
       " 'Vimeo': 4,\n",
       " 'produce high quality corrugated cardboard packaging': 4,\n",
       " 'leading independent cardboard box manufacturer': 4,\n",
       " 'distinctive corrugated cardboard packaging': 4,\n",
       " 'making corrugated packaging across': 4,\n",
       " 'house award winning structural': 4,\n",
       " 'Scroll': 4,\n",
       " 'independent corrugated cardboard packaging specialists products': 0,\n",
       " 'leading independent uk cardboard box manufacturer': 0,\n",
       " 'uk cardboard box manufacturer making': 0,\n",
       " 'ireland wide delivery fleet': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages.ner_list[4].get_salience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n4j=Neo4j(webpages.ner_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added to graph: 23\n"
     ]
    }
   ],
   "source": [
    "n4j.add_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"json\") == False:\n",
    "    !mkdir json\n",
    "\n",
    "for i in range(webpages.get_number_of_urls()):\n",
    "    json_text = webpages.ner_list[i].jsonify()\n",
    "    json_file = open(\"json/\" + webpages.ner_list[i].url,'w')\n",
    "    json_file.write(json_text)\n",
    "    json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = [\"www.google.com\",\"www.balsejfnweo.cofm\"]\n",
    "np.savetxt(\"test_file.txt\", test_file, delimiter=\"\\n\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Everything(unittest.TestCase):\n",
    " \n",
    "    def test_url(self):\n",
    "        \n",
    "        obj = Extract(\"www.google.com\")\n",
    "        obj = Extract(\"test_file.txt\")\n",
    "        self.assertEqual(obj.get_number_of_urls(), 2)\n",
    "        self.assertEqual(str(obj.bad_urls[0]), \"http://www.balsejfnweo.cofm\")\n",
    "        \n",
    "    def test_ner_extraction(self):\n",
    "        \n",
    "        obj = Extract(\"test_file.txt\")\n",
    "        self.assertIsNone(obj.ner_list)\n",
    "        obj.extract_entities()\n",
    "        self.assertIsNotNone(obj.ner_list)\n",
    "        \n",
    "    def test_ner_class(self):\n",
    "        \n",
    "        obj = Extract(\"test_file.txt\")\n",
    "        obj.extract_entities()\n",
    "        \n",
    "        with self.assertRaises(IndexError):\n",
    "            obj.ner_list[2].url\n",
    "            \n",
    "        self.assertIsNotNone(obj.ner_list[0].jsonify())\n",
    "        self.assertIsNotNone(obj.ner_list[0].get_salience())\n",
    "    \n",
    "    def test_neo4j(self):\n",
    "        obj = Extract(\"test_file.txt\")\n",
    "        obj.extract_entities()\n",
    "        \n",
    "        self.assertIsNotNone(obj.ner_list)\n",
    "        for i in webpages.ner_list:\n",
    "            n4j=Neo4j(i)\n",
    "            n4j.add_nodes(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_neo4j (__main__.Test_Everything) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='www.balsejfnweo.cofm', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fae3ade4240>: Failed to establish a new connection: [Errno -2] Name or service not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57753), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57755), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57757), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57759), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57761), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57763), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57765), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57767), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/aa5118/anaconda3/envs/plural/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.147', 57769), raddr=('52.19.19.82', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added to graph: 1\n",
      "Nodes added to graph: 10\n",
      "Nodes added to graph: 11\n",
      "Nodes added to graph: 16\n",
      "Nodes added to graph: 23\n",
      "Nodes added to graph: 7\n",
      "Nodes added to graph: 6\n",
      "Nodes added to graph: 29\n",
      "Nodes added to graph: 8\n",
      "Could not parse text\n",
      "Nodes added to graph: 81\n",
      "Could not parse text\n",
      "Nodes added to graph: 1\n",
      "Nodes added to graph: 1\n",
      "Nodes added to graph: 18\n",
      "Nodes added to graph: 13\n",
      "Nodes added to graph: 16\n",
      "Nodes added to graph: 2\n",
      "Nodes added to graph: 7\n",
      "Nodes added to graph: 17\n",
      "Nodes added to graph: 2\n",
      "Nodes added to graph: 1\n",
      "Nodes added to graph: 27\n",
      "Nodes added to graph: 5\n",
      "Nodes added to graph: 13\n",
      "Nodes added to graph: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_ner_class (__main__.Test_Everything) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added to graph: 1\n",
      "HTTPConnectionPool(host='www.balsejfnweo.cofm', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fae3acb84e0>: Failed to establish a new connection: [Errno -2] Name or service not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_ner_extraction (__main__.Test_Everything) ... ok\n",
      "test_url (__main__.Test_Everything) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='www.balsejfnweo.cofm', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fae3add7f28>: Failed to establish a new connection: [Errno -2] Name or service not known'))\n",
      "HTTPConnectionPool(host='www.balsejfnweo.cofm', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fae3addf908>: Failed to establish a new connection: [Errno -2] Name or service not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 268.640s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fae3b667f28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
