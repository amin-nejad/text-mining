{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/aa5118/anaconda3/envs/plural/lib/python3.7/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import requests\n",
    "import justext\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import wikipedia\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedEntityRecognition:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \n",
    "        self.url = url\n",
    "        self.companies = []\n",
    "        self.people = []\n",
    "        self.keywords = []\n",
    "        self.locations = []\n",
    "        self.events = []\n",
    "        self.products = []\n",
    "        self.text = None\n",
    "        self.doc = None\n",
    "        \n",
    "    def visualise(self):\n",
    "        \n",
    "        if str(self.doc) != \"\":\n",
    "            return displacy.render(self.doc, style=\"ent\", jupyter=True)\n",
    "        else:\n",
    "            return \"No entities found.\"\n",
    "    \n",
    "    def jsonify(self):\n",
    "        \n",
    "        list_of_entities = [self.companies, self.people, self.keywords, self.locations, self.events, self.products]\n",
    "        list_of_entity_types = [\"companies\", \"people\", \"keywords\", \"locations\", \"events\", \"products\"]\n",
    "        zip_object = zip(list_of_entity_types, list_of_entities)\n",
    "        entity_dict = dict(zip_object)\n",
    "        \n",
    "        return json.dumps(entity_dict, indent = 4, ensure_ascii=False)\n",
    "    \n",
    "    def get_people_wiki_pages(self):\n",
    "        \n",
    "        wiki = []\n",
    "        \n",
    "        for person in self.people:\n",
    "            try:\n",
    "                result = wikipedia.page(person)\n",
    "                summary = wikipedia.summary(person, sentences=1)\n",
    "                wiki.append([result.url, summary])\n",
    "            except:\n",
    "                wiki.append([\"\",\"\"])\n",
    "        zip_object = zip(self.people, wiki)\n",
    "        \n",
    "        return dict(zip_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        sources=pd.read_csv(filename,header=None,names=[\"url\"])\n",
    "        #sources=sources.append({\"url\":\"www.balsejfnweo.com\"}, ignore_index = True) \n",
    "        \n",
    "        self.sources = sources.head(10)\n",
    "        self.bad_urls = []\n",
    "        self.extracted = self.__extract_text()\n",
    "        self.ner_list = None\n",
    "        \n",
    "        if \"__remove_whitespace_entities\" not in (dict(nlp.pipeline).keys()):\n",
    "            nlp.add_pipe(self.__remove_whitespace_entities, after='ner')\n",
    "\n",
    "    def __extract_text(self):\n",
    "        \n",
    "        extracted=[]\n",
    "        for url in self.sources['url']:\n",
    "\n",
    "            url = \"http://\"+url\n",
    "            \n",
    "            try:\n",
    "                html = requests.get(url)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self.bad_urls.append(url)\n",
    "                print (e)\n",
    "                \n",
    "            if str(html) == \"<Response [200]>\":\n",
    "                \n",
    "                text = \"\"\n",
    "                paragraphs = justext.justext(html.text.encode('utf-8'), justext.get_stoplist(\"English\"))\n",
    "                for paragraph in paragraphs:\n",
    "                    if not paragraph.is_boilerplate:\n",
    "                        text+= paragraph.text + \"\\n\"\n",
    "            else:\n",
    "                text=\"<ERROR>\"\n",
    "\n",
    "            extracted.append(text)\n",
    "\n",
    "        return extracted\n",
    "    \n",
    "    def __remove_whitespace_entities(self, doc):\n",
    "        doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "        return doc\n",
    "    \n",
    "    def extract_entities(self):\n",
    "        \n",
    "        ner_list=[]\n",
    "        r = Rake()\n",
    "        k = 10 #top number of key words to extract\n",
    "\n",
    "        for i, url in enumerate(self.sources['url']):\n",
    "            ner_list.append(NamedEntityRecognition(url))\n",
    "            \n",
    "            ner_list[i].text = self.extracted[i]\n",
    "            r.extract_keywords_from_text(ner_list[i].text)\n",
    "            top_k_keywords = [value for value in dict(r.get_ranked_phrases_with_scores()[:k]).values()]\n",
    "            ner_list[i].keywords = top_k_keywords\n",
    "            \n",
    "            doc = nlp(self.extracted[i])\n",
    "            ner_list[i].doc = doc\n",
    "            \n",
    "            for entity in doc.ents:\n",
    "                if (entity.label_ == \"ORG\"):\n",
    "                    ner_list[i].companies.append(entity.text)\n",
    "                elif (entity.label_ == \"PERSON\"):\n",
    "                    ner_list[i].people.append(entity.text)\n",
    "                elif (entity.label_ == \"GPE\"):\n",
    "                    ner_list[i].locations.append(entity.text)            \n",
    "                elif (entity.label_ == \"EVENT\"):\n",
    "                    ner_list[i].events.append(entity.text)        \n",
    "                elif (entity.label_ == \"PRODUCT\"):\n",
    "                    ner_list[i].products.append(entity.text)\n",
    "        \n",
    "        self.ner_list = ner_list\n",
    "        return\n",
    "        \n",
    "    def get_number_of_urls(self):\n",
    "        return len(self.sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Extract(\"./sources.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.bad_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['tank storage facilities harnessing', 'supplying high grade', 'high ffa products', 'argent energy', 'green fuel']\n",
      "['today manual operations run alongside robotic', 'attract major clients', 'day one asg', 'latest manufacturing technology', 'asg group', 'truly world']\n",
      "['commercial director experience matters aston martin works ltd aston martin works limited', 'principal firm allows aston martin works limited', 'automotive compliance ltd ’', 'automotive compliance ltd', 'financial conduct authority', 'finance providers']\n",
      "['produce high quality corrugated cardboard packaging', 'independent corrugated cardboard packaging specialists products', 'leading independent uk cardboard box manufacturer', 'leading independent cardboard box manufacturer', 'uk cardboard box manufacturer making', 'distinctive corrugated cardboard packaging', 'making corrugated packaging across', 'ireland wide delivery fleet', 'house award winning structural', 'corrugated cardboard packaging']\n",
      "['ddudjuilp atos thought leadership blog august 9', 'latest global automotive executive survey found', 'new paradigm recent years', 'surveyed consumers say ownership', 'full uk driver ’', 'latest digital vision', 'marked shift away', 'continue using cookies', 'financially stable business']\n",
      "['best possible online experience', 'cookie policy', 'use cookies', 'cookies', 'manage']\n",
      "['iso 14001 accreditations supplying automotive nvh sealing solutions', 'highly motivated world class work force', 'avon group – one vision', 'engineered sealing solutions', 'one goal –', 'global leading provider']\n",
      "['ayrshire metals limited welcome', 'ayrshire metals limited', 'highest industry standards', '100 years', 'proud']\n",
      "['barrie beard ltd du ... monarch aircraft engineering – ian radford double click', 'dan par ... mr southwell – droitwich – november 2016', 'carefu ... helen chambers – bromsgrove – march 2018', 'knowledgea ... ann brazier – worcestershire july 2019', 'information please contact dan cattell 01527 875172', 'leave us feedback barrie beard ltd fans', '01527 875172 shop opening times monday', 'monarch aircraft engineering ltd', 'dan ... network rail –', '... lynn messenger july 2019']\n"
     ]
    }
   ],
   "source": [
    "test.extract_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barrie Beard',\n",
       " 'Accredited Contractor',\n",
       " 'Worksafe Contractor Membership',\n",
       " 'Rob Davenport',\n",
       " 'Rob',\n",
       " 'Ann Brazier – Worcestershire',\n",
       " 'Lynn',\n",
       " 'Chris Smith',\n",
       " 'Lynn Messenger',\n",
       " 'Helen Chambers',\n",
       " 'Rob Davenport (BB Electrician',\n",
       " 'Rob',\n",
       " 'Helen Chambers – Bromsgrove – March',\n",
       " 'Mark Warman',\n",
       " 'Dan Par',\n",
       " 'Dan',\n",
       " 'Dan Cattell']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ner_list[9].people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No entities found.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ner_list[0].visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"companies\": [\n",
      "        \"The Independent Corrugated Cardboard Packaging\\nSpecialists\\nProducts\\n\",\n",
      "        \"Innovation, Leadership, Team work and Excellence\"\n",
      "    ],\n",
      "    \"people\": [\n",
      "        \"Atlas Packaging\",\n",
      "        \"Vimeo\"\n",
      "    ],\n",
      "    \"keywords\": [],\n",
      "    \"locations\": [\n",
      "        \"UK\",\n",
      "        \"Devon\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Ireland\",\n",
      "        \"UK\",\n",
      "        \"UK\",\n",
      "        \"Scroll\"\n",
      "    ],\n",
      "    \"events\": [],\n",
      "    \"products\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(test.ner_list[4].jsonify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
